name: Test OpenGrep Action

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  # Test basic functionality across architectures
  test-basic:
    name: Basic Tests - ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, ubuntu-24.04]
        include:
          - os: ubuntu-latest
            arch: X64
          - os: ubuntu-24.04
            arch: X64
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Create test fixtures
        run: |
          mkdir -p test-fixtures

          # Create a simple vulnerable JavaScript file
          cat > test-fixtures/test.js << 'EOF'
          // Intentional security issues for testing
          const password = "hardcoded_password_123";
          eval(userInput);
          const sql = "SELECT * FROM users WHERE id = " + userId;
          EOF

          # Create a Python test file
          cat > test-fixtures/test.py << 'EOF'
          # Security test cases
          password = "admin123"
          exec(user_input)
          EOF

      - name: Test basic scan with JSON output
        id: test-json
        uses: ./
        with:
          paths: 'test-fixtures'
          output-format: 'json'
          output-file: 'results-json.json'
          fail-on-findings: 'false'
          verify-signature: 'true'
          upload-artifacts: 'false'

      - name: Verify JSON output exists
        run: |
          if [ ! -f "${{ steps.test-json.outputs.results-file }}" ]; then
            echo "ERROR: JSON results file not found"
            exit 1
          fi
          echo "JSON results file created successfully"

          # Verify it's valid JSON
          if command -v jq >/dev/null 2>&1; then
            if ! jq empty "${{ steps.test-json.outputs.results-file }}" 2>/dev/null; then
              echo "ERROR: Invalid JSON in results file"
              exit 1
            fi
            echo "JSON is valid"
          fi

      - name: Test SARIF output
        id: test-sarif
        uses: ./
        with:
          paths: 'test-fixtures'
          output-format: 'sarif'
          output-file: 'results.sarif'
          fail-on-findings: 'false'
          verify-signature: 'false'  # Skip verification for speed
          upload-artifacts: 'false'

      - name: Verify SARIF output
        run: |
          if [ ! -f "${{ steps.test-sarif.outputs.results-file }}" ]; then
            echo "ERROR: SARIF results file not found"
            exit 1
          fi
          echo "SARIF results file created successfully"

      - name: Test text output
        id: test-text
        uses: ./
        with:
          paths: 'test-fixtures'
          output-format: 'text'
          output-file: 'results.txt'
          fail-on-findings: 'false'
          verify-signature: 'false'
          upload-artifacts: 'false'

      - name: Check outputs are set
        run: |
          echo "Results file: ${{ steps.test-json.outputs.results-file }}"
          echo "Findings count: ${{ steps.test-json.outputs.findings-count }}"
          echo "Critical count: ${{ steps.test-json.outputs.critical-count }}"

          if [ -z "${{ steps.test-json.outputs.results-file }}" ]; then
            echo "ERROR: results-file output not set"
            exit 1
          fi

  # Test configuration options
  test-config:
    name: Configuration Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Create test code
        run: |
          mkdir -p src tests
          echo "const pwd = 'test123';" > src/app.js
          echo "const test = 'safe';" > tests/test.js

      - name: Test with exclusions
        uses: ./
        with:
          paths: 'src tests'
          exclude: 'tests'
          output-format: 'json'
          fail-on-findings: 'false'
          verify-signature: 'false'
          upload-artifacts: 'false'

      - name: Test severity filtering - ERROR only
        uses: ./
        with:
          paths: 'src'
          severity: 'ERROR'
          output-format: 'json'
          fail-on-findings: 'false'
          verify-signature: 'false'
          upload-artifacts: 'false'

      - name: Test severity filtering - WARNING
        uses: ./
        with:
          paths: 'src'
          severity: 'WARNING'
          output-format: 'json'
          fail-on-findings: 'false'
          verify-signature: 'false'
          upload-artifacts: 'false'

      - name: Test with custom timeout
        uses: ./
        with:
          paths: 'src'
          timeout: '300'
          output-format: 'json'
          fail-on-findings: 'false'
          verify-signature: 'false'
          upload-artifacts: 'false'

  # Test security features
  test-security:
    name: Security Features
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Test signature verification enabled
        uses: ./
        with:
          paths: '.'
          output-format: 'json'
          verify-signature: 'true'
          fail-on-findings: 'false'
          upload-artifacts: 'false'

      - name: Test signature verification disabled
        uses: ./
        with:
          paths: '.'
          output-format: 'json'
          verify-signature: 'false'
          fail-on-findings: 'false'
          upload-artifacts: 'false'

      - name: Test with different OpenGrep version
        uses: ./
        with:
          version: 'v1.10.2'
          paths: '.'
          output-format: 'json'
          verify-signature: 'true'
          fail-on-findings: 'false'
          upload-artifacts: 'false'

  # Test caching behavior
  test-caching:
    name: Caching Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: First run (cache miss)
        uses: ./
        with:
          paths: '.'
          output-format: 'json'
          verify-signature: 'false'
          fail-on-findings: 'false'
          upload-artifacts: 'false'

      - name: Second run (cache hit)
        uses: ./
        with:
          paths: '.'
          output-format: 'json'
          verify-signature: 'false'
          fail-on-findings: 'false'
          upload-artifacts: 'false'

  # Test error handling
  test-errors:
    name: Error Handling
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Test with invalid version (should fail gracefully)
        id: test-invalid-version
        continue-on-error: true
        uses: ./
        with:
          version: 'v999.999.999'
          paths: '.'
          output-format: 'json'
          verify-signature: 'false'
          fail-on-findings: 'false'
          upload-artifacts: 'false'

      - name: Verify error was handled
        run: |
          if [ "${{ steps.test-invalid-version.outcome }}" != "failure" ]; then
            echo "ERROR: Action should have failed with invalid version"
            exit 1
          fi
          echo "Invalid version handled correctly"

      - name: Test with nonexistent path
        id: test-invalid-path
        continue-on-error: true
        uses: ./
        with:
          paths: '/nonexistent/path'
          output-format: 'json'
          verify-signature: 'false'
          fail-on-findings: 'false'
          upload-artifacts: 'false'

  # Test fail-on-findings behavior
  test-fail-on-findings:
    name: Fail on Findings
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Create vulnerable code
        run: |
          mkdir -p vulnerable
          echo "const apiKey = 'sk_live_123456789';" > vulnerable/app.js

      - name: Test fail-on-findings disabled
        id: test-no-fail
        uses: ./
        with:
          paths: 'vulnerable'
          output-format: 'json'
          fail-on-findings: 'false'
          verify-signature: 'false'
          upload-artifacts: 'false'

      - name: Test fail-on-findings enabled (should fail)
        id: test-fail
        continue-on-error: true
        uses: ./
        with:
          paths: 'vulnerable'
          output-format: 'json'
          fail-on-findings: 'true'
          verify-signature: 'false'
          upload-artifacts: 'false'

      - name: Verify workflow failed when findings detected
        run: |
          if [ "${{ steps.test-fail.outcome }}" == "success" ]; then
            echo "WARNING: Expected failure with fail-on-findings=true and vulnerable code"
            echo "This might mean no findings were detected or fail-on-findings logic has issues"
          fi

  # Test artifact upload
  test-artifacts:
    name: Artifact Upload
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Test with artifact upload enabled
        uses: ./
        with:
          paths: '.'
          output-format: 'json'
          upload-artifacts: 'true'
          artifact-name: 'test-results-artifact-upload-enabled'
          verify-signature: 'false'
          fail-on-findings: 'false'

      - name: Test with artifact upload disabled
        uses: ./
        with:
          paths: '.'
          output-format: 'json'
          upload-artifacts: 'false'
          verify-signature: 'false'
          fail-on-findings: 'false'

  # Summary job
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-basic, test-config, test-security, test-caching, test-errors, test-fail-on-findings, test-artifacts]
    if: always()
    steps:
      - name: Check test results
        run: |
          echo "Test Basic: ${{ needs.test-basic.result }}"
          echo "Test Config: ${{ needs.test-config.result }}"
          echo "Test Security: ${{ needs.test-security.result }}"
          echo "Test Caching: ${{ needs.test-caching.result }}"
          echo "Test Errors: ${{ needs.test-errors.result }}"
          echo "Test Fail on Findings: ${{ needs.test-fail-on-findings.result }}"
          echo "Test Artifacts: ${{ needs.test-artifacts.result }}"

          if [ "${{ needs.test-basic.result }}" != "success" ] || \
             [ "${{ needs.test-config.result }}" != "success" ] || \
             [ "${{ needs.test-security.result }}" != "success" ]; then
            echo "CRITICAL TESTS FAILED"
            exit 1
          fi

          echo "All critical tests passed!"
